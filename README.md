# Confluence Semantic Search Prep (concept, v2)

Концепт-скрипт для подготовки данных из Confluence (7.19.x) под семантический поиск:
- забирает страницы через REST API (rendered HTML: `body.view`)
- парсит HTML в блоки по правилам (h*, p/div/blockquote/pre, ul/ol→li, table→строки)
- собирает блоки в чанки (по умолчанию 512 токенов) **без индексации** в Milvus/OpenSearch
- сохраняет результат в JSON

## Запуск

```bash
python -m venv .venv
. .venv/bin/activate
pip install -r requirements.txt
cp .env_example .env_example
python run.py
```

## Что улучшено в v2 (в сравнении с предыдущим концептом)

- При дроблении больших блоков сохраняется **валидная HTML/Markdown структура**:
  - списки: каждая часть оборачивается в `<ul>/<ol> + <li>...</li>`
  - таблицы: каждая часть оборачивается в `<table>` и включает заголовок (если есть) + строку данных;
    при дроблении по предложениям создаётся строка `<td colspan=N>...</td>` и заголовок сохраняется
- При дроблении блоков создаются **новые блоки** с новыми `block_index` и `block_id` (как в вашей спецификации)
- `page_text_normalized`, `char_start/char_end` считаются уже по *финальным* блокам, чтобы координаты совпадали

## Про токены

По умолчанию используется быстрый приблизительный счётчик токенов (регулярка).
Для строгого подсчёта можно включить стратегию `hf` и указать путь к локальному токенизатору
(требует `transformers`, не включён в requirements по умолчанию).
